{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a76ef935",
   "metadata": {},
   "source": [
    "# Welcome to the Prompt Engineering Workshop\n",
    "Let's first install the pre-requisite python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755d359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas is a library for parsing CSVs\n",
    "!pip install pandas\n",
    "# also as we will be using Claude, hence we need to install anthropic\n",
    "!pip install anthropic\n",
    "# and for testing we need a testing framework\n",
    "!pip install pytest "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30512c2e",
   "metadata": {},
   "source": [
    "We will be generating code for parsing some CSVs so let's create the CSV file to work with quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630ba75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For workshop purposes, so that everyone can access the same data, we are writing the file dynamically\n",
    "import csv\n",
    "\n",
    "def create_csv(file_name):\n",
    "    # Create data as list of lists\n",
    "    data = [\n",
    "        [\"Flow ID\",\"Tx Frames\",\"Rx Frames\",\"Frames Delta\",\"Loss %\",\"Tx Frame Rate\",\"Rx Frame Rate\",\"Tx L1 Rate (bps)\",\"Rx L1 Rate (bps)\",\"Rx Bytes\",\"Tx Rate (Bps)\",\"Rx Rate (Bps)\",\"Tx Rate (bps)\",\"Rx Rate (bps)\",\"Tx Rate (Kbps)\",\"Rx Rate (Kbps)\",\"Tx Rate (Mbps)\",\"Rx Rate (Mbps)\",\"Store-Forward Avg Latency (ns)\",\"Store-Forward Min Latency (ns)\",\"Store-Forward Max Latency (ns)\",\"First TimeStamp\",\"Last TimeStamp\"],\n",
    "        [\"Flow 1\",1000,1000,0,0.000,0.000,0.000,0.000,0.000,66000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0,0,0,\"00:00:01.063\",\"00:00:04.393\"],\n",
    "        [\"Flow 2\",1000,100,0,0.000,0.000,0.000,0.000,0.000,66000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0,0,0,\"00:00:01.063\",\"00:00:04.393\"],\n",
    "        [\"Flow 3\",1000,500,0,0.000,0.000,0.000,0.000,0.000,66000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0,0,0,\"00:00:01.063\",\"00:00:04.393\"],\n",
    "        [\"Flow 4\",1000,\"N/A\",0,0.000,0.000,0.000,0.000,0.000,66000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0,0,0,\"00:00:01.063\",\"00:00:04.393\"]\n",
    "    ]\n",
    "\n",
    "    # Write to CSV file\n",
    "    with open(file_name, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(data)\n",
    "\n",
    "create_csv(\"stats.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc9fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether the file is created\n",
    "!cat stats.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1834d1",
   "metadata": {},
   "source": [
    "## Let's get started with our first prompt\n",
    "### Level 1: The \"Zero-Shot\"\n",
    "Asking the model to perform a task with no examples, no context, and no constraints. You are relying entirely on the model's training data assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e627544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import AnthropicFoundry\n",
    "import re\n",
    "\n",
    "def extract_and_save_python_code(text, output_file='output.py'):\n",
    "    # Pattern to match ```python ... ``` blocks\n",
    "    pattern = r'```python\\s*(.*?)```'\n",
    "    \n",
    "    # Find all matches (re.DOTALL allows . to match newlines)\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    \n",
    "    # Join all code blocks if multiple exist\n",
    "    python_code = '\\n\\n'.join(matches)\n",
    "    \n",
    "    # Write to file\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(python_code)\n",
    "    \n",
    "    return python_code\n",
    " \n",
    "def get_response_from_llm(prompt, token_limit=1024):\n",
    "    message = client.messages.create(\n",
    "        model=deployment_name,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=token_limit,\n",
    "    )\n",
    "    return message.content[0].text\n",
    "\n",
    "# API Configuration\n",
    "endpoint = \"https://foundary-codegen-1.services.ai.azure.com/anthropic/\"\n",
    "deployment_name = \"claude-sonnet-4-5\"\n",
    "api_key = \"\"\n",
    "\n",
    "client = AnthropicFoundry(\n",
    "    api_key=api_key,\n",
    "    base_url=endpoint\n",
    ")\n",
    "\n",
    "prompt = \"\"\"\n",
    "Write a python script to read a csv file called 'stats.csv' \n",
    "calculate the total loss by looking at Tx Frames and Rx Frames.\n",
    "I want you to calculate loss as (tx - rx) / tx * 100 and print the result for all Flow 2, Flow3 and Flow 4.\n",
    "we will have multiple columns but the relevant columns are Flow ID, Tx Frames, Rx Frames.\n",
    "return only the python code without any explanation or comments.\n",
    "\"\"\"\n",
    "\n",
    "response = get_response_from_llm(prompt)\n",
    "print(response)\n",
    "extract_and_save_python_code(response, output_file='traffic_loss_calculator.py')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dabd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's run the python code generated by the model\n",
    "!python traffic_loss_calculator.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2931eef",
   "metadata": {},
   "source": [
    "got an error right ! Do you know why ? because the LLM is not at all aware of the format of your csv\n",
    "\n",
    "### Level 2: The \"Few-Shot\"\n",
    "Providing examples (shots) of the input data and the desired output format. This guides the model's pattern recognition engine to handle data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c25193",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Write a python script to read a csv file called 'stats.csv' \n",
    "Calculate the total loss by looking at Tx Frames and Rx Frames.\n",
    "I want you to calculate loss as (tx - rx) / tx * 100 and print the result for all Flow 2, Flow3 and Flow 4.\n",
    "We will have multiple columns but the relevant columns are Flow ID, Tx Frames, Rx Frames.\n",
    "\n",
    "Its a messy csv\n",
    "Here is how my csv looks like partially:\n",
    "\"Flow ID\",\"Tx Frames\",\"Rx Frames\"\n",
    "\"Flow 1\",1000,1000,....\n",
    "\"Flow 2\",1000,\"N/A\",....\n",
    ".\n",
    ".\n",
    ".\n",
    "\"Flow N\",1000,200,....\n",
    "\n",
    "Return only the python code without any explanation or comments.\n",
    "\"\"\"\n",
    "\n",
    "response = get_response_from_llm(prompt)\n",
    "print(response)\n",
    "extract_and_save_python_code(response, output_file='traffic_loss_calculator2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5bcf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets run the new code generated by the model\n",
    "!python traffic_loss_calculator2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1514c9",
   "metadata": {},
   "source": [
    "Nice right! but it still has a lot of things it cannot handle , like proper type casts, missing rows, missing files etc\n",
    "This leads to \n",
    "\n",
    "### Level 3: Chain of Thought\n",
    "\n",
    "Forcing the model to \"Show its work\" or verbalize reasoning before generating code. This reduces hallucination and ensures edge cases are considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691104a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Write a python script to read a csv file called 'stats.csv' \n",
    "Calculate the total loss by looking at Tx Frames and Rx Frames.\n",
    "I want you to calculate loss as (tx - rx) / tx * 100 and print the result for all Flow 2, Flow3 and Flow 4.\n",
    "We will have multiple columns but the relevant columns are Flow ID, Tx Frames, Rx Frames.\n",
    "\n",
    "Its a messy csv\n",
    "Here is how my csv looks like partially:\n",
    "\"Flow ID\",\"Tx Frames\",\"Rx Frames\"\n",
    "\"Flow 1\",1000,1000,....\n",
    "\"Flow 2\",1000,\"N/A\",....\n",
    ".\n",
    ".\n",
    ".\n",
    "\"Flow N\",1000,200,....\n",
    "\n",
    "Before coding, consider the following edge cases and handle them in your code:\n",
    "1. How do we handle missing files?\n",
    "2. How do we handle non-numeric rows?\n",
    "3. How do we safely convert types?\n",
    "\n",
    "Return only the python code without any explanation or comments.\n",
    "\"\"\"\n",
    "\n",
    "response = get_response_from_llm(prompt, token_limit=2048)\n",
    "print(response)\n",
    "extract_and_save_python_code(response, output_file='traffic_loss_calculator3.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccde0f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's now delete the file and see if the new code handles it gracefully and returns proper error message\n",
    "!rm stats.csv\n",
    "!python traffic_loss_calculator3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d37b33",
   "metadata": {},
   "source": [
    "Seems pretty neat !, but is it maintainable ? Is it like a code written by someone senior ?\n",
    "\n",
    "### Level 4: Role + Constraints\n",
    "\n",
    "Assigning a Persona (Senior Engineer) and strict Constraints (Standards) to force production-quality structure and formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9942d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create the csv again as we deleted it in previous step\n",
    "create_csv(\"stats.csv\")\n",
    "\n",
    "prompt = \"\"\"\n",
    "Write a python script to read a csv file called 'stats.csv' \n",
    "Calculate the total loss by looking at Tx Frames and Rx Frames.\n",
    "I want you to calculate loss as (tx - rx) / tx * 100 and print the result for all Flow 2, Flow3 and Flow 4.\n",
    "We will have multiple columns but the relevant columns are Flow ID, Tx Frames, Rx Frames.\n",
    "\n",
    "Its a messy csv\n",
    "Here is how my csv looks like partially:\n",
    "\"Flow ID\",\"Tx Frames\",\"Rx Frames\"\n",
    "\"Flow 1\",1000,1000,....\n",
    "\"Flow 2\",1000,\"N/A\",....\n",
    ".\n",
    ".\n",
    ".\n",
    "\"Flow N\",1000,200,....\n",
    "\n",
    "Before coding, consider the following edge cases and handle them in your code:\n",
    "1. How do we handle missing files?\n",
    "2. How do we handle non-numeric rows?\n",
    "3. How do we safely convert types?\n",
    "\n",
    "Act as a Senior Engineer.\n",
    "Constraints:\n",
    "1. Use `argparse` for CLI usage.\n",
    "2. Use Type Hinting (PEP 484).\n",
    "3. Use `logging` instead of print.\n",
    "4. Modular functions.\n",
    "\n",
    "Return only the python code without any explanation or comments.\n",
    "\"\"\"\n",
    "response = get_response_from_llm(prompt, token_limit=2048)\n",
    "print(response)\n",
    "extract_and_save_python_code(response, output_file='traffic_loss_calculator4.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a116e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's run the generated code to see if it works\n",
    "!python traffic_loss_calculator4.py --file stats.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da421bb1",
   "metadata": {},
   "source": [
    "Great! nice formatting, but is it scalable can it handle 50GB size of CSV ?\n",
    "\n",
    "### Level 5: Reflection (Optimization)\n",
    "\n",
    "Asking the model to critique its own work for performance or security flaws before generating the final code. This catches hidden issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1180ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Write a python script to read a csv file called 'stats.csv' \n",
    "Calculate the total loss by looking at Tx Frames and Rx Frames.\n",
    "I want you to calculate loss as (tx - rx) / tx * 100 and print the result for all Flow 2, Flow3 and Flow 4.\n",
    "We will have multiple columns but the relevant columns are Flow ID, Tx Frames, Rx Frames.\n",
    "\n",
    "Its a messy csv\n",
    "Here is how my csv looks like partially:\n",
    "\"Flow ID\",\"Tx Frames\",\"Rx Frames\"\n",
    "\"Flow 1\",1000,1000,....\n",
    "\"Flow 2\",1000,\"N/A\",....\n",
    ".\n",
    ".\n",
    ".\n",
    "\"Flow N\",1000,200,....\n",
    "\n",
    "Before coding, consider the following edge cases and handle them in your code:\n",
    "1. How do we handle missing files?\n",
    "2. How do we handle non-numeric rows?\n",
    "3. How do we safely convert types?\n",
    "\n",
    "Act as a Senior Engineer.\n",
    "Constraints:\n",
    "1. Use `argparse` for CLI usage.\n",
    "2. Use Type Hinting (PEP 484).\n",
    "3. Use `logging` instead of print.\n",
    "4. Modular functions.\n",
    "\n",
    "Critique your initial plan for **Memory Safety** assuming a 50GB file size.\n",
    "Correction: Rewrite logic to be memory efficient\n",
    "\n",
    "Return only the python code without any explanation or comments.\n",
    "\"\"\"\n",
    "response = get_response_from_llm(prompt, token_limit=2048)\n",
    "print(response)\n",
    "extract_and_save_python_code(response, output_file='traffic_loss_calculator5.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769151e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the new code for memory efficiency\n",
    "!python traffic_loss_calculator5.py --file stats.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c7fd46",
   "metadata": {},
   "source": [
    "Now you have a memory efficient , fully structured well documented functioning code ! but is it ?\n",
    "There are other approaches right ? We just considered one. are there other better approaches ?\n",
    "\n",
    "### Level 6: Tree of Thoughts\n",
    "\n",
    "Generating multiple solutions, evaluating the trade-offs (Pros/Cons) of each, and deliberately selecting the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0e2602",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('traffic_loss_calculator5.py', 'r') as f:\n",
    "    code_content = f.read()\n",
    "\n",
    "prompt = f\"\"\"\n",
    "For my use-case of parsing a csv file which can go upto 50GB in size,\n",
    "you provided me a well structured code earlier. Now I want you to review the code for memory efficiency.\n",
    "\n",
    "Step 1: Brainstorm 3 approaches (Pandas vs CSV Lib vs Polars).\n",
    "Step 2: Evaluate Pros/Cons for a **microservice with low memory**.\n",
    "Step 3: Pick the winner and change the code accordingly.\n",
    "\n",
    "Here is the code:\n",
    "{code_content}\n",
    "\n",
    "explain why you chose the approach and tradeoffs with other approaches.\n",
    "when explaining the approach do not use ``python ... ``` block. it should be plain text.\n",
    "Then return the final python code within ```python ... ``` block. it should appear only once. \n",
    "\"\"\"\n",
    "\n",
    "response = get_response_from_llm(prompt, token_limit=3000)\n",
    "print(response)\n",
    "# first we need to save the response in md so that we can see the explanation as well as code properly\n",
    "with open('code_review_traffic_loss_calculator.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(response)\n",
    "\n",
    "# now lets extract the code and save it to a new file\n",
    "extract_and_save_python_code(response, output_file='traffic_loss_calculator6.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c420f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the new code is still running fine\n",
    "!python traffic_loss_calculator6.py --file stats.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b1c53c",
   "metadata": {},
   "source": [
    "At this time everything seems complete right ? but have we tested all the error scenarios ?\n",
    "Lets generate Test cases but with a different prompt format\n",
    "\n",
    "### Level 7: Decomposition\n",
    "\n",
    "Breaking a large request into **structural components** (Architecture, Interface, Implementation). This moves from scripting to software engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fba508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "We have created a python script to read a csv file called 'stats.csv'\n",
    "The code is saved with filename 'traffic_loss_calculator5.py'.\n",
    "and we can execute it as: python traffic_loss_calculator5.py --file stats.csv \n",
    "Here is the code:\n",
    "{code_content}\n",
    "\n",
    "I want to generate unit tests for this code using simple python functions and pytest framework.\n",
    "Let's break down the task which needs to be done.\n",
    "1. Analyze the code and identify key areas we can test\n",
    "2  Create test cases where you will creating mock data to simulate different scenarios and call the python code.\n",
    "4. please ensure if you are creating mock data files, you clean them up after the test is done.\n",
    "3. Finally combine all the test -cases maybe 3or 4 in number in a single python file.\n",
    "\n",
    "\n",
    "Return only the python code within ```python ... ``` block.\n",
    "\"\"\"\n",
    "response = get_response_from_llm(prompt, token_limit=4000)\n",
    "print(response)\n",
    "\n",
    "extract_and_save_python_code(response, output_file='check_loss_calculator.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726c4d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the test now \n",
    "!pytest -s -v check_loss_calculator.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1d7aa8",
   "metadata": {},
   "source": [
    "Now we have unit test to actually test each part of the code.\n",
    "Finally coming up with this prompt is something you need to do a lot of stuff \n",
    "Is there a standard way where we can get a structure a build upon it ?\n",
    "\n",
    "### Level 8: Meta-Prompting\n",
    "\n",
    "The Force Multiplier. Instead of writing the code prompt yourself, you ask the AI to write the perfect prompt for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f67a9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"You are a prompt engineering expert.\n",
    "Generate a prompt to achieve this use-case :\n",
    "We have a python script to read a csv file called 'stats.csv' the code should memory efficient and handle edge cases.\n",
    "The prompt should instruct that code quality should be modular and of senior engineer level.\n",
    "\"\"\"\n",
    "\n",
    "response = get_response_from_llm(prompt)\n",
    "print(response)\n",
    "\n",
    "with open('prompt.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
