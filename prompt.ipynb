{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a76ef935",
   "metadata": {},
   "source": [
    "# Welcome to the Prompt engineering Workshop\n",
    "Lets first install the pre-requite python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755d359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas is a library for parsing csvs\n",
    "!pip install pandas\n",
    "# also as we will be using claude we need to install anthropic\n",
    "!pip install anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30512c2e",
   "metadata": {},
   "source": [
    "We will generating code for parsing some csv so lets create the csv to work with quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "630ba75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# For Workshop purpose so that everyone can acess the same data, we writing the file dynamically \n",
    "import csv\n",
    "\n",
    "# Create data as list of lists\n",
    "data = [\n",
    "    [\"Flow ID\",\"Tx Frames\",\"Rx Frames\",\"Frames Delta\",\"Loss %\",\"Tx Frame Rate\",\"Rx Frame Rate\",\"Tx L1 Rate (bps)\",\"Rx L1 Rate (bps)\",\"Rx Bytes\",\"Tx Rate (Bps)\",\"Rx Rate (Bps)\",\"Tx Rate (bps)\",\"Rx Rate (bps)\",\"Tx Rate (Kbps)\",\"Rx Rate (Kbps)\",\"Tx Rate (Mbps)\",\"Rx Rate (Mbps)\",\"Store-Forward Avg Latency (ns)\",\"Store-Forward Min Latency (ns)\",\"Store-Forward Max Latency (ns)\",\"First TimeStamp\",\"Last TimeStamp\"],\n",
    "    [\"Flow 1\",1000,1000,0,0.000,0.000,0.000,0.000,0.000,66000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0,0,0,\"00:00:01.063\",\"00:00:04.393\"],\n",
    "    [\"Flow 2\",1000,100,0,0.000,0.000,0.000,0.000,0.000,66000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0,0,0,\"00:00:01.063\",\"00:00:04.393\"],\n",
    "    [\"Flow 3\",1000,1500,0,0.000,0.000,0.000,0.000,0.000,66000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0,0,0,\"00:00:01.063\",\"00:00:04.393\"],\n",
    "    [\"Flow 4\",1000,\"N/A\",0,0.000,0.000,0.000,0.000,0.000,66000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0.000,0,0,0,\"00:00:01.063\",\"00:00:04.393\"]\n",
    "]\n",
    "\n",
    "# Write to CSV file\n",
    "with open('stats.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc9fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the file is created\n",
    "!cat stats.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1834d1",
   "metadata": {},
   "source": [
    "## Lets get started with our first prompt\n",
    "### Level 1: The \"Zero-Shot\"\n",
    "Asking the model to perform a task with no examples, no context, and no constraints. You are relying entirely on the model's training data assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e627544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import AnthropicFoundry\n",
    "import re\n",
    "\n",
    "def extract_and_save_python_code(text, output_file='output.py'):\n",
    "    # Pattern to match ```python ... ``` blocks\n",
    "    pattern = r'```python\\s*(.*?)```'\n",
    "    \n",
    "    # Find all matches (re.DOTALL allows . to match newlines)\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    \n",
    "    # Join all code blocks if multiple exist\n",
    "    python_code = '\\n\\n'.join(matches)\n",
    "    \n",
    "    # Write to file\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(python_code)\n",
    "    \n",
    "    return python_code\n",
    "\n",
    "# API Configuration\n",
    "endpoint = \"https://foundary-codegen-1.services.ai.azure.com/anthropic/\"\n",
    "deployment_name = \"claude-sonnet-4-5\"\n",
    "api_key = \"\"\n",
    "\n",
    "client = AnthropicFoundry(\n",
    "    api_key=api_key,\n",
    "    base_url=endpoint\n",
    ")\n",
    "\n",
    "prompt = \"\"\"\n",
    "Write a python script to read a csv file called 'stats.csv' \n",
    "calculate the total loss by looking at Tx Frames and Rx Frames.\n",
    "I want you to calculate loss as (rx - tx) / tx * 100 and print the result for all Flow 2, Flow3 and Flow 4.\n",
    "we will havve multiple columns but the relevant columns are Flow ID, Tx Frames, Rx Frames.\n",
    "return only the python code without any explanation or comments.\n",
    "\"\"\"\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    max_tokens=1024,\n",
    ")\n",
    "\n",
    "print(message.content[0].text)\n",
    "extract_and_save_python_code(message.content[0].text, output_file='traffic_loss_calculator.py')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dabd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets run the python code generated by the model\n",
    "!python traffic_loss_calculator.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
